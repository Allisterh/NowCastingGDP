@article{Botha2021,
   abstract = {Given lags in the release of data, a central bank must ‘nowcast’ current GDP using available quarterly or higher frequency data to understand the current state of economic activity. This paper uses various statistical modelling techniques to draw on a large number of series to nowcast South African GDP. We also show that GDP volatility has increased markedly over the last 5 years, making GDP forecasting more difficult. We show that all the models developed, as well as the Reserve Bank’s official forecasts, have tended to over-estimate GDP growth over this period. However, several of the statistical nowcasting models we present in this paper provide competitive nowcasts relative to the official Reserve Bank and market analysts’ nowcasts. We also demonstrate the usefulness of statistical models in quantifying forecast uncertainty and interpreting data surprises.},
   author = {Byron Botha and Tim Olds and Geordie Reid and Daan Steenkamp and Rossouw Jaarsveld},
   doi = {10.1111/saje.12298},
   issn = {0038-2280},
   issue = {February},
   journal = {South African Journal of Economics},
   month = {9},
   pages = {1-39},
   title = {Nowcasting South African gross domestic product using a suite of statistical models},
   url = {https://www.resbank.co.za/en/home/publications/publication-detail-pages/working-papers/2021/NowcastingSouthAfricanGDPusingasuiteofstatisticalmodels https://onlinelibrary.wiley.com/doi/10.1111/saje.12298},
   year = {2021},
}
@article{Babii2021,
   abstract = {This article introduces structured machine learning regressions for high-dimensional time series data potentially sampled at different frequencies. The sparse-group LASSO estimator can take advantage of such time series data structures and outperforms the unstructured LASSO. We establish oracle inequalities for the sparse-group LASSO estimator within a framework that allows for the mixing processes and recognizes that the financial and the macroeconomic data may have heavier than exponential tails. An empirical application to nowcasting US GDP growth indicates that the estimator performs favorably compared to other alternatives and that text data can be a useful addition to more traditional numerical data. Our methodology is implemented in the R package midasml, available from CRAN.},
   author = {Andrii Babii and Eric Ghysels and Jonas Striaukas},
   doi = {10.1080/07350015.2021.1899933},
   issn = {15372707},
   journal = {Journal of Business and Economic Statistics},
   keywords = {Fat tails,High-dimensional time series,Mixed-frequency data,Sparse-group LASSO,Tau-mixing,Textual news data},
   title = {Machine Learning Time Series Regressions With an Application to Nowcasting},
   year = {2021},
}
@article{Babii2020,
   abstract = {This paper introduces structured machine learning regressions for high-dimensional time series data potentially sampled at different frequencies. The sparse-group LASSO estimator can take advantage of such time series data structures and outperforms the unstructured LASSO. We establish oracle inequalities for the sparse-group LASSO estimator within a framework that allows for the mixing processes and recognizes that the financial and the macroeconomic data may have heavier than exponential tails. An empirical application to nowcasting US GDP growth indicates that the estimator performs favorably compared to other alternatives and that the text data can be a useful addition to more traditional numerical data.},
   author = {Andrii Babii and Eric Ghysels and Jonas Striaukas},
   keywords = {and,and statistics conference,at the tse toulouse,finance,forecasting conference,fuk-nagaev inequality,high-dimensional time series,machine learning in econometrics,mixed frequency data,sparse-group lasso,tau-dependent processes,text data,the big data and,the financial econometrics conference,the jrc big data,we thank participants at},
   title = {Machine learning time series regressions with an application to nowcasting},
   url = {http://arxiv.org/abs/2005.14057},
   year = {2020},
}
@article{Woloszko2020,
   author = {By Nicolas Woloszko and Policy Studies Branch},
   pages = {1-43},
   title = {ADAPTIVE TREES : A NEW APPROACH TO ECONOMIC FORECASTING},
   year = {2020},
}
@article{Cepni2020,
   abstract = {In this paper, we assess the predictive content of latent economic policy uncertainty and data surprise factors for forecasting and nowcasting gross domestic product (GDP) using factor-type econometric models. Our analysis focuses on five emerging market economies: Brazil, Indonesia, Mexico, South Africa, and Turkey; and we carry out a forecasting horse race in which predictions from various different models are compared. These models may (or may not) contain latent uncertainty and surprise factors constructed using both local and global economic datasets. The set of models that we examine in our experiments includes both simple benchmark linear econometric models as well as dynamic factor models that are estimated using a variety of frequentist and Bayesian data shrinkage methods based on the least absolute shrinkage operator (LASSO). We find that the inclusion of our new uncertainty and surprise factors leads to superior predictions of GDP growth, particularly when these latent factors are constructed using Bayesian variants of the LASSO. Overall, our findings point to the importance of spillover effects from global uncertainty and data surprises, when predicting GDP growth in emerging market economies.},
   author = {Oguzhan Cepni and I. Ethem Guney and Norman R. Swanson},
   doi = {10.1002/for.2602},
   issn = {1099131X},
   issue = {1},
   journal = {Journal of Forecasting},
   keywords = {economic policy uncertainty,emerging markets,factor model,forecasting,lasso,shrinkage},
   pages = {18-36},
   title = {Forecasting and nowcasting emerging market GDP growth rates: The role of latent global economic policy uncertainty and macroeconomic data surprise factors},
   volume = {39},
   year = {2020},
}
@article{,
   abstract = {The assessment of macroeconomic conditions in real time is challenging. Dynamic factor models, which summarize the comovement across many macroeconomic time series as driven by a small number of shocks, have become the workhorse tool for 'nowcasting' activity. This paper develops a novel dynamic factor model that explicitly captures three salient features of modern business cycles: low frequency movements in long-run growth and volatility, lead-lag patterns in the responses of variables to common shocks, and fat-tailed outliers. We use real-time unrevised data for the last two decades and cloud computing technology to conduct an out-of-sample evaluation exercise of the model. The exercise demonstrates the importance of considering these features for forecasting and probability assessment of economic conditions. In an application to the COVID-19 recession, we develop a method to incorporate newly available high-frequency data. The use of such alternative data is essential to track the downturn in activity, but a careful econometric specification is just as important.},
   author = {Juan Antolin-Diaz and Thomas Drechsel and Ivan Petrella},
   doi = {10.2139/ssrn.3669854},
   journal = {SSRN Electronic Journal},
   keywords = {at the nber summer,bayesian inference in economet-,bayesian methods,c32,daily economic index,dynamic factor models,e01,e23,e32,fat tails,institute,jel classification numbers,nowcasting,o47,real-time data,the nber-nsf seminar in,we thank seminar participants},
   title = {Advances in Nowcasting Economic Activity: Secular Trends, Large Shocks and New Data},
   year = {2020},
}
@article{Ferrara2019,
   abstract = {Nowcasting GDP growth is extremely useful for policy-makers to assess macroe-conomic conditions in real-time. In this paper, we aim at nowcasting euro area GDP with a large database of Google search data. Our objective is to check whether this specific type of information can be useful to increase GDP nowcasting accuracy, and when, once we control for official variables. In this respect, we estimate shrunk bridge regressions that integrate Google data optimally screened through a targeting method, and we empirically show that this approach provides some gain in pseudo-real-time nowcasting of euro area GDP quarterly growth. Especially, we get that Google data bring useful information for GDP nowcasting for the four first weeks of the quarter when macroeconomic information is lacking. However, as soon as official data become available, their relative nowcasting power vanishes. In addition, a true real-time anal-ysis confirms that Google data constitute a reliable alternative when official data are lacking.},
   author = {Laurent Ferrara and Anna Simoni},
   doi = {10.2139/ssrn.3370917},
   issn = {1556-5068},
   journal = {SSRN Electronic Journal},
   keywords = {and data day,big data,comments,ecb,ecb conference on macro,forecasting with large datasets,francesca monti,giorgio primiceri,google search data,hal varian and the,hec conference for useful,michele lenza,nowcasting,participants of the 10th,ridge regularization,sheng,simon,sure independence screening,thank per nymand-andersen,thank roberto golinelli,we would like to},
   pages = {1-28},
   title = {When Are Google Data Useful to Nowcast Gdp? An Approach Via Pre-Selection and Shrinkage},
   year = {2019},
}
@article{Personal2019,
   author = {Munich Personal and Repec Archive},
   issue = {95885},
   title = {Munich Personal RePEc Archive From Twitter to GDP : Estimating Economic Activity From Social Media From Twitter to GDP : Estimating Economic Activity From Social Media},
   year = {2019},
}
@article{Plag2019,
   author = {Lisa-marie Plag},
   title = {Bachelor Thesis : BSc 2 Econometrics & Economics Predicting South African GDP Growth Rates Using Factor Models and Machine Learning Techniques},
   year = {2019},
}
@article{Bybee2019,
   abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-α-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 Å for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
   author = {Leland Bybee and Bryan T. Kelly and Asaf Manela and Dacheng Xiu},
   doi = {10.2139/ssrn.3446225},
   issn = {1556-5068},
   journal = {SSRN Electronic Journal},
   keywords = {and seminar and conference,and yale,attention,bob shiller,chicago,jesse shapiro,lasse pedersen,machine learning,macroeconomic news,nyu,participants at aqr,textual analysis,toby moskowitz,var,volatility,wall street journal,we benefitted from discussions,will goetzmann,with rob engle},
   title = {The Structure of Economic News},
   year = {2019},
}
@article{Richardson2019,
   author = {Adam Richardson and Thomas Van and Florenstein Mulder and Tuğrul Vehbi},
   isbn = {2009Q12019Q1},
   issue = {November},
   keywords = {Forecast evaluation.,Machine learning,Nowcasting},
   title = {Nowcasting GDP using machine learning algorithms: A real-time assessment},
   url = {https://www.rbnz.govt.nz/about-us/the-journey-of-te-putea-matua-our-tane-mahuta},
   year = {2019},
}
@article{Ferrara2019,
   abstract = {Assessing accurately global economic conditions is a great challenge for economists. The International Monetary Fund proposes within its periodic World Economic Outlook report a measure of the global GDP annual growth, that is generally considered as the benchmark nowcast by macroeconomists. In this paper, we put forward an alternative approach to provide monthly nowcasts of the annual global growth rate. Our approach builds on a Factor-Augmented MIxed DAta Sampling (FA-MIDAS) model that enables: (i) to account for a large monthly database including various countries and sectors of the global economy and (ii) to nowcast a low-frequency macroeconomic variable using higher frequency information. Pseudo-real-time results over the period 2010–16 show that this approach provides reliable and timely nowcasts of the world GDP annual growth on a monthly basis.},
   author = {Laurent Ferrara and Clément Marsilli},
   doi = {10.1111/twec.12708},
   issn = {14679701},
   issue = {3},
   journal = {World Economy},
   keywords = {IMF,Nowcasting,factor-augmented MIDAS,global growth},
   pages = {846-875},
   title = {Nowcasting global economic growth: A factor-augmented mixed-frequency approach},
   volume = {42},
   year = {2019},
}
@article{,
   abstract = {Interest in the use of “big data” when it comes to forecasting macroeconomic time series such as private consumption or unemployment has increased; however, applications to the forecasting of GDP remain rather rare. This paper incorporates Google search data into a bridge equation model, a version of which usually belongs to the suite of forecasting models at central banks. We show how such big data information can be integrated, with an emphasis on the appeal of the underlying model in this respect. As the decision as to which Google search terms should be added to which equation is crucial —- both for the forecasting performance itself and for the economic consistency of the implied relationships —- we compare different (ad-hoc, factor and shrinkage) approaches in terms of their pseudo real time out-of-sample forecast performances for GDP, various GDP components and monthly activity indicators. We find that sizeable gains can indeed be obtained by using Google search data, where the best-performing Google variable selection approach varies according to the target variable. Thus, assigning the selection methods flexibly to the targets leads to the most robust outcomes overall in all layers of the system.},
   author = {Thomas B. Götz and Thomas A. Knetsch},
   doi = {10.1016/j.ijforecast.2018.08.001},
   issn = {01692070},
   issue = {1},
   journal = {International Journal of Forecasting},
   keywords = {Big data,Boosting,Bridge equation models,Forecasting,LASSO,Partial least squares,Principal components analysis},
   pages = {45-66},
   publisher = {Elsevier B.V.},
   title = {Google data in bridge equation models for German GDP},
   volume = {35},
   url = {https://doi.org/10.1016/j.ijforecast.2018.08.001},
   year = {2019},
}
@article{Cepni2019,
   abstract = {This paper contributes to the nascent literature on nowcasting and forecasting GDP in emerging market economies using big data methods. This is done by analyzing the usefulness of various dimension-reduction, machine learning and shrinkage methods, including sparse principal component analysis (SPCA), the elastic net, the least absolute shrinkage operator, and least angle regression when constructing predictions using latent global macroeconomic and financial factors (diffusion indexes) in a dynamic factor model (DFM). We also utilize a judgmental dimension-reduction method called the Bloomberg Relevance Index (BRI), which is an index that assigns a measure of importance to each variable in a dataset depending on the variable's usage by market participants. Our empirical analysis shows that, when specified using dimension-reduction methods (particularly BRI and SPCA), DFMs yield superior predictions relative to both benchmark linear econometric models and simple DFMs. Moreover, global financial and macroeconomic (business cycle) diffusion indexes constructed using targeted predictors are found to be important in four of the five emerging market economies that we study (Brazil, Mexico, South Africa, and Turkey). These findings point to the importance of spillover effects across emerging market economies, and underscore the significance of characterizing such linkages parsimoniously when utilizing high-dimensional global datasets.},
   author = {Oguzhan Cepni and I. Ethem Güney and Norman R. Swanson},
   doi = {10.1016/j.ijforecast.2018.10.008},
   issn = {01692070},
   issue = {2},
   journal = {International Journal of Forecasting},
   keywords = {Diffusion index,Dimension reduction methods,Emerging markets,Factor model,Forecasting,Variable selection},
   pages = {555-572},
   publisher = {Elsevier B.V.},
   title = {Nowcasting and forecasting GDP in emerging markets using global financial and macroeconomic diffusion indexes},
   volume = {35},
   url = {https://doi.org/10.1016/j.ijforecast.2018.10.008},
   year = {2019},
}
@article{Bontempi2019,
   author = {Maria Elena Bontempi and Michele Frigeri and Roberto Golinelli and Matteo Squadrani},
   doi = {10.2139/ssrn.3469503},
   issn = {1556-5068},
   journal = {SSRN Electronic Journal},
   keywords = {finance-based indexes,google,internet searches,macroeconomic uncertainty measurement,news-based indexes,perception of uncertainty,survey-based indexes,trends},
   title = {Uncertainty, Perception and the Internet},
   year = {2019},
}
@article{Bok2018,
   abstract = {Data, data, data…. Economists know their importance well, especially when it comes to monitoring macroeconomic conditions—the basis for making informed economic and policy decisions. Handling large and complex data sets was a challenge that macroeconomists engaged in real-time analysis faced long before so-called big data became pervasive in other disciplines. We review how methods for tracking economic conditions using big data have evolved over time and explain how econometric techniques have advanced to mimic and automate best practices of forecasters on trading desks, at central banks, and in other market-monitoring roles. We present in detail the methodology underlying the New York Fed Staff Nowcast, which employs these innovative techniques to produce early estimates of GDP growth, synthesizing a wide range of macroeconomic data as they become available.},
   author = {Brandyn Bok and Daniele Caratelli and Domenico Giannone and Argia M. Sbordone and Andrea Tambalotti},
   doi = {10.1146/annurev-economics-080217-053214},
   issn = {1941-1383},
   issue = {1},
   journal = {Annual Review of Economics},
   pages = {615-643},
   title = {Macroeconomic Nowcasting and Forecasting with Big Data},
   volume = {10},
   year = {2018},
}
@article{Buono2018,
   abstract = {This paper aims at providing a primer on the use of big data in macroe-conomic nowcasting and early estimation, with a special focus on the use in official Statistical Agencies and similar institutions. We discuss: (i) a typology of big data characteristics relevant for Macroeconomic Nowcasting and early estimates, (ii) various methods for feature extraction of big data sources to usable time series format, (iii) econometric methodologies which could be used for nowcasting with big data, (iv) empirical nowcasting results and gains in terms of increased timeliness for three key target variables in four countries, and (v) various ways to evaluate and present nowcast estimates. We conclude by providing a set of recommendations to assess the pros and cons of the use of big data in a specific empirical context.},
   author = {Dario Buono and George Kapetanios and Massimiliano Marcellino and Gian Luigi Mazzi and Fotis Papailias},
   journal = {16th Conference of the International Association of Official Statisticians},
   keywords = {Early Estimated,Econometric Methods,Nowcasting,big data},
   title = {Evaluation of Nowcasting / Flash Estimation based on a Big Set of Indicators},
   url = {https://cdn0.scrvt.com/08ab3606b0b7a8ea53fd0b40b1c44f86/04af65675247cd40/5958bd4d026f/p145-Basnayake.pdf},
   year = {2018},
}
@article{Richardson2018,
   abstract = {This paper analyses the real-time nowcasting performance of machine learning algorithms estimated on New Zealand data. Using a large set of real-time quarterly macroeconomic indicators, we train a range of popular machine learning algorithms and nowcast real GDP growth for each quarter over the 2009Q1-2018Q1 period. We compare the predictive accuracy of these nowcasts with that of other traditional univariate and multivariate statistical models. We find that the machine learning algorithms outperform the traditional statistical models. Moreover, combining the individual machine learning nowcasts further improves the performance than in the case of the individual nowcasts alone. Abstract This paper analyses the real-time nowcasting performance of machine learning al},
   author = {Adam Richardson and Thomas Mulder and Tugru l Vehbi},
   doi = {10.2139/ssrn.3256578},
   issue = {July},
   journal = {SSRN Electronic Journal},
   pages = {23-26},
   title = {Nowcasting New Zealand GDP using machine learning algorithms},
   year = {2018},
}
@article{,
   author = {Juan Antolín-Díaz and Thomas Drechsel and Ivan Petrella},
   title = {Advances in Nowcasting   Economic Activity},
   url = {http://personal.lse.ac.uk/drechsel/papers/ADP2_slides.pdf},
   year = {2018},
}
@article{Kapetanios2018,
   author = {George Kapetanios and Fotis Papailias and others},
   issue = {July},
   journal = {Economic Statistics Centre of Excellence, National Institute of Economic and Social Research},
   title = {Big data & macroeconomic nowcasting: Methodological review},
   year = {2018},
}
@article{Richardson2018,
   abstract = {This paper provides a discussion of the use of Big Data for economic forecasting and a critical review of recent empirical studies drawing on Big Data sources, including those using internet search, social media and financial transactions related data. A broad conclusion is that whilst Big Data sources may provide new and unique insights into high frequency macroeconomic activities, their uses for macroeconomic forecasting are relatively limited and have met with varying degrees of success. Specific issues arise from the limitations of these data sets, the qualitative nature of the information they incorporate and the empirical testing frameworks used. The most successful applications appear to be those which seek to embed this class of information within a coherent economic framework, as opposed to a naïve black box statistical approach. This suggests that future work using Big Data should focus on improving the quality and accessibility of the relevant data sets and in developing more appropriate economic modelling frameworks for their future use.},
   author = {Pete Richardson},
   doi = {10.24187/ecostat.2018.505d.1966},
   issn = {17775574},
   issue = {505-506},
   journal = {Economie et Statistique},
   keywords = {Big Data,Internet search,Macroeconomic forecasting,Models,Nowcasting,Short-term},
   pages = {65-87},
   title = {Nowcasting and the use of big data in short-term macroeconomic forecasting: A critical review},
   volume = {2018},
   year = {2018},
}
@article{Giannone2018,
   abstract = {We compare sparse and dense representations of predictive models in macroeconomics, microeconomics, and finance. To deal with a large number of possible predictors, we specify a prior that allows for both variable selection and shrinkage. The posterior distribution does not typically concentrate on a single sparse or dense model, but on a wide set of models. A clearer pattern of sparsity can only emerge when models of very low dimension are strongly favored a priori. },
   author = {Domenico Giannone and Michele Lenza and Giorgio E. Primiceri},
   doi = {10.2139/ssrn.3166281},
   issue = {847},
   journal = {SSRN Electronic Journal},
   title = {Economic Predictions with Big Data: The Illusion of Sparsity},
   year = {2018},
}
@article{Kim2018,
   abstract = {A number of recent studies in the economics literature have focused on the usefulness of factor models in the context of prediction using “big data” (see Bai and Ng, 2008; Dufour and Stevanovic, 2010; Forni, Hallin, Lippi, & Reichlin, 2000; Forni et al., 2005; Kim and Swanson, 2014a; Stock and Watson, 2002b, 2006, 2012, and the references cited therein). We add to this literature by analyzing whether “big data” are useful for modelling low frequency macroeconomic variables, such as unemployment, inflation and GDP. In particular, we analyze the predictive benefits associated with the use of principal component analysis (PCA), independent component analysis (ICA), and sparse principal component analysis (SPCA). We also evaluate machine learning, variable selection and shrinkage methods, including bagging, boosting, ridge regression, least angle regression, the elastic net, and the non-negative garotte. Our approach is to carry out a forecasting “horse-race” using prediction models that are constructed based on a variety of model specification approaches, factor estimation methods, and data windowing methods, in the context of predicting 11 macroeconomic variables that are relevant to monetary policy assessment. In many instances, we find that various of our benchmark models, including autoregressive (AR) models, AR models with exogenous variables, and (Bayesian) model averaging, do not dominate specifications based on factor-type dimension reduction combined with various machine learning, variable selection, and shrinkage methods (called “combination” models). We find that forecast combination methods are mean square forecast error (MSFE) “best” for only three variables out of 11 for a forecast horizon of h=1, and for four variables when h=3 or 12. In addition, non-PCA type factor estimation methods yield MSFE-best predictions for nine variables out of 11 for h=1, although PCA dominates at longer horizons. Interestingly, we also find evidence of the usefulness of combination models for approximately half of our variables when h>1. Most importantly, we present strong new evidence of the usefulness of factor-based dimension reduction when utilizing “big data” for macroeconometric forecasting.},
   author = {Hyun Hak Kim and Norman R. Swanson},
   doi = {10.1016/j.ijforecast.2016.02.012},
   issn = {01692070},
   issue = {2},
   journal = {International Journal of Forecasting},
   keywords = {Bagging,Bayesian model averaging,Boosting,Elastic net and non-negative garotte,Independent component analysis,Least angle regression,Prediction,Ridge regression,Sparse principal component analysis},
   pages = {339-354},
   publisher = {Elsevier B.V.},
   title = {Mining big data using parsimonious factor, machine learning, variable selection and shrinkage methods},
   volume = {34},
   url = {http://dx.doi.org/10.1016/j.ijforecast.2016.02.012},
   year = {2018},
}
@article{Wehrmann2017,
   abstract = {Most work on tweet sentiment analysis is mono-lingual and the models that are generated by machine learning strategies do not generalize across multiple languages. Cross-language sentiment analysis is usually performed through machine translation approaches that translate a given source language into the target language of choice. Machine translation is expensive and the results that are provided by theses strategies are limited by the quality of the translation that is performed. In this paper, we propose a language-agnostic translation-free method for Twitter sentiment analysis, which makes use of deep convolutional neural networks with character-level embeddings for pointing to the proper polarity of tweets that may be written in distinct (or multiple) languages. The proposed method is more accurate than several other deep neural architectures while requiring substantially less learnable parameters. The resulting model is capable of learning latent features from all languages that are employed during the training process in a straightforward fashion and it does not require any translation process to be performed whatsoever. We empirically evaluate the efficiency and effectiveness of the proposed approach in tweet corpora based on tweets from four different languages, showing that our approach comfortably outperforms the baselines. Moreover, we visualize the knowledge that is learned by our method to qualitatively validate its effectiveness for tweet sentiment classification.},
   author = {Joonatas Wehrmann and Willian Becker and Henry E.L. Cagnini and Rodrigo C. Barros},
   doi = {10.1109/IJCNN.2017.7966145},
   isbn = {9781509061815},
   journal = {Proceedings of the International Joint Conference on Neural Networks},
   keywords = {Character-based Embedding,Convolutional Neural Networks,Deep Learning,Sentiment Analysis,Twitter},
   pages = {2384-2391},
   title = {A character-based convolutional neural network for language-agnostic Twitter sentiment analysis},
   volume = {2017-May},
   year = {2017},
}
@article{Buono2017,
   abstract = {(1) Eurostat. (2) retired from Eurostat. (3) King's College London.},
   author = {Dario Buono and Gian Luigi Mazzi and George Kapetanios and Massimiliano Marcellino},
   issue = {July},
   journal = {Eurona},
   keywords = {big data,data features,nowcasting},
   pages = {93-145},
   title = {Big data types for macroeconomic nowcasting},
   volume = {1},
   url = {https://ec.europa.eu/eurostat/cros/system/files/euronaissue1-2017-art4.pdf},
   year = {2017},
}
@article{Castelnuovo2017,
   abstract = {We develop uncertainty indices for the United States and Australia based on freely accessible, real time Google Trends data. Our Google Trends Uncertainty (GTU) indices are found to be positively correlated to a variety of alternative proxies for uncertainty available for these two countries. VAR investigations document an economically and statistically significant contribution to unemployment dynamics by GTU shocks in the United States. In contrast, the contribution of GTU shocks to unemployment dynamics in Australia is found to be much milder and substantially lower than that of monetary policy shocks.},
   author = {Efrem Castelnuovo and Trung Duc Tran},
   doi = {10.2139/ssrn.3050294},
   issue = {27},
   journal = {SSRN Electronic Journal},
   title = {Google It Up! A Google Trends-Based Uncertainty Index for the United States and Australia},
   year = {2017},
}
@article{Lo2017,
   abstract = {The ability to analyse online user-generated content related to sentiments (e.g., thoughts and opinions) on products or policies has become a de-facto skillset for many companies and organisations. Besides the challenge of understanding formal textual content, it is also necessary to take into consideration the informal and mixed linguistic nature of online social media languages, which are often coupled with localised slang as a way to express ‘true’ feelings. Due to the multilingual nature of social media data, analysis based on a single official language may carry the risk of not capturing the overall sentiment of online content. While efforts have been made to understand multilingual sentiment analysis based on a range of informal languages, no significant electronic resource has been built for these localised languages. This paper reviews the various current approaches and tools used for multilingual sentiment analysis, identifies challenges along this line of research, and provides several recommendations including a framework that is particularly applicable for dealing with scarce resource languages.},
   author = {Siaw Ling Lo and Erik Cambria and Raymond Chiong and David Cornforth},
   doi = {10.1007/s10462-016-9508-4},
   issn = {15737462},
   issue = {4},
   journal = {Artificial Intelligence Review},
   keywords = {Multilingual analysis,Scarce resource languages,Sentiment analysis,Social media},
   pages = {499-527},
   publisher = {Springer Netherlands},
   title = {Multilingual sentiment analysis: from formal to informal and scarce resource languages},
   volume = {48},
   year = {2017},
}
@article{Kabundi2016,
   author = {Alain Kabundi and Elmarie Nel and Franz Ruch},
   issue = {581},
   journal = {ERSA Working Paper},
   title = {Nowcasting Real GDP growth in South Africa},
   url = {http://www.econrsa.org/system/files/publications/working_papers/working_paper_581.pdf},
   year = {2016},
}
@article{Onorante2016,
   abstract = {Many recent papers have investigated whether data from internet search engines such as Google can help improve nowcasts or short-term forecasts of macroeconomic variables. These papers construct variables based on Google searches and use them as explanatory variables in regression models. We add to this literature by nowcasting using dynamic model selection (DMS) meth-ods which allow for model switching between time-varying parameter regression models. This is potentially useful in an environment of coefficient instability and over-parameterization which can arise when forecasting with Google vari-ables. We extend the DMS methodology by allowing for the model switching to be controlled by the Google variables through what we call Google probabil-ities. That is, instead of using Google variables as regressors, we allow them to determine which nowcasting model should be used at each point in time. In an empirical exercise involving nine major monthly US macroeconomic variables, we find DMS methods to provide large improvements in nowcasting. Our use of Google model probabilities within DMS often performs better than conventional DMS.},
   author = {Luca Onorante and Gary Koop},
   doi = {10.4995/carma2016.2016.4213},
   issue = {October},
   keywords = {do not necessarily re,dynamic model av-,ecb,ect those of the,eraging,google,internet search data,not be reported as,nowcasting,of the authors and,representing the views of,state space model,the,the ecb,this working paper should,views expressed are those},
   title = {Macroeconomic Nowcasting Using Google Probabilities},
   year = {2016},
}
@article{,
   abstract = {With the advancement of web technology and its growth, there is a huge volume of data present in the web for internet users and a lot of data is generated too. Internet has become a platform for online learning, exchanging ideas and sharing opinions. Social networking sites like Twitter, Facebook, Google+ are rapidly gaining popularity as they allow people to share and express their views about topics, have discussion with different communities, or post messages across the world. There has been lot of work in the field of sentiment analysis of twitter data. This survey focuses mainly on sentiment analysis of twitter data which is helpful to analyze the information in the tweets where opinions are highly unstructured, heterogeneous and are either positive or negative, or neutral in some cases. In this paper, we provide a survey and a comparative analyses of existing techniques for opinion mining like machine learning and lexicon-based approaches, together with evaluation metrics. Using various machine learning algorithms like Naive Bayes, Max Entropy, and Support Vector Machine, we provide research on twitter data streams.We have also discussed general challenges and applications of Sentiment Analysis on Twitter. Keywords Twitter, Sentiment analysis (SA), Opinion mining, Machine learning, Naive Bayes (NB), Maximum Entropy, Support Vector Machine (SVM).},
   author = {Vishal A. and S.S. Sonawane},
   doi = {10.5120/ijca2016908625},
   issue = {11},
   journal = {International Journal of Computer Applications},
   keywords = {learning,machine,maximum entropy,naive bayes,nb,opinion mining,sa,sentiment analysis,support,svm,twitter,vector machine},
   pages = {5-15},
   title = {Sentiment Analysis of Twitter Data: A Survey of Techniques},
   volume = {139},
   year = {2016},
}
@article{Argueta2015,
   abstract = {Social networking sites have flooded the Internet with posts containing shared opinions, moods, and feelings. This has given rise to a new wave of research to develop algorithms for emotion detection and extraction on social data. As the desire to understand how people feel about certain events/objects across countries or regions grows, the need to analyze social data in different lan- guages grows with it. However, the explosive nature of data generated around the world brings a challenge for sentiment-based information retrieval and analysis. In this paper, we propose a multilingual system with a computationally inexpensive approach to sentiment analysis of so- cial data. The experiments demonstrate that our approach performs an effective multi-lingual sentiment analysis of microblog data with little more than a 100 emotion-bearing patterns. 1},
   author = {Carlos Argueta and Yi-Shin Chen},
   doi = {10.3115/v1/w14-5906},
   issue = {101},
   pages = {38-43},
   title = {Multi-Lingual Sentiment Analysis of Social Data Based on Emotion-Bearing Patterns},
   year = {2015},
}
@article{,
   abstract = {We develop a framework for measuring and monitoring business cycles in real time. Following a long tradition in macroeconometrics, inference is based on a variety of indicators of economic activity, treated as imperfect measures of an underlying index of business cycle conditions. We extend existing approaches by permitting for heterogenous lead-lag patterns of the various indicators along the business cycles. The framework is well suited for high-frequency monitoring of current economic conditions in real time-nowcasting-since inference can be conducted in presence of mixed frequency data and irregular patterns of data availability. Our assessment of the underlying index of business cycle conditions is accurate and more timely than popular alternatives, including the Chicago Fed National Activity Index (CFNAI). A formal real-time forecasting evaluation shows that the framework produces well-calibrated probability nowcasts that resemble the consensus assessment of the Survey of Professional Forecasters. JEL Classification: C11, C32, C38, E32, E38.},
   author = {Antonello D’Agostino and Domenico Giannone and Michele Lenza and Michele Modugno},
   doi = {10.17016/feds.2015.066},
   issn = {19362854},
   issue = {066},
   journal = {Finance and Economics Discussion Series},
   pages = {1-25},
   title = {Nowcasting Business Cycles: a Bayesian Approach to Dynamic Heterogeneous Factor Models},
   volume = {2015},
   year = {2015},
}
@article{,
   author = {Dorine Lawrence-Hughes},
   journal = {UCLA Electronic Theses and Dissertations},
   title = {UCLA UCLA Electronic Theses and Dissertations},
   year = {2014},
}
@article{Higgins2014,
   abstract = {This paper documents GDPNow, a "nowcasting" model for gross domestic product (GDP) growth that synthesizes the "bridge equation" approach relating GDP subcomponents to monthly source data with the factor model approach used by Giannone, Reichlin, and Small (2008). The GDPNow model forecasts GDP growth by aggregating 13 subcomponents that make up GDP with the chain-weighting methodology used by the U.S. Bureau of Economic Analysis. Using current vintage data, out-of-sample GDPNow model forecasts are found to be more accurate than a number of statistical benchmarks since 2000. Using real-time data since the second-half of 2011, GDPNow model forecasts are found to be only slightly inferior to consensus near-term GDP forecasts from Blue Chip Economic Indicators. The forecast error variance of GDP growth for each of the GDPNow model, Blue Chip, and the Federal Reserve staff's Green Book is decomposed as the sum of the forecast error covariances for the contributions to growth of the subcomponents of GDP. The decompositions show that "net exports" and "change in private inventories" are particularly difficult subcomponents to nowcast.},
   author = {Higgins and Patrick C.},
   issue = {July},
   journal = {FRB Atlanta Working Paper},
   keywords = {forecasting,macroeconometric forecasting,nowcasting},
   title = {GDPNow: A Model for GDP Nowcasting},
   year = {2014},
}
@article{Kim2014,
   abstract = {In this paper, we empirically assess the predictive accuracy of a large group of models that are specified using principle components and other shrinkage techniques, including Bayesian model averaging and various bagging, boosting, least angle regression and related methods. Our results suggest that model averaging does not dominate other well designed prediction model specification methods, and that using "hybrid" combination factor/shrinkage methods often yields superior predictions. More specifically, when using recursive estimation windows, which dominate other "windowing" approaches, "hybrid" models are mean square forecast error "best" around 1/3 of the time, when used to predict 11 key macroeconomic indicators at various forecast horizons. Baseline linear (factor) models also "win" around 1/3 of the time, as do model averaging methods. Interestingly, these broad findings change noticeably when considering different sub-samples. For example, when used to predict only recessionary periods, "hybrid" models "win" in 7 of 11 cases, when condensing findings across all "windowing" approaches, estimation methods, and models, while model averaging does not "win" in a single case. However, in expansions, and during the 1990s, model averaging wins almost 1/2 of the time. Overall, combination factor/shrinkage methods "win" approximately 1/2 of the time in 4 of 6 different sample periods. Ancillary findings based on our forecasting experiments underscore the advantages of using recursive estimation strategies, and provide new evidence of the usefulness of yield and yield-spread variables in nonlinear prediction model specification. © 2013 Elsevier B.V. All rights reserved.},
   author = {Hyun Hak Kim and Norman R. Swanson},
   doi = {10.1016/j.jeconom.2013.08.033},
   issn = {03044076},
   issue = {PART 2},
   journal = {Journal of Econometrics},
   keywords = {Bagging,Bayesian model averaging,Boosting,Diffusion index,Elastic net,Forecasting,Least angle regression,Non-negative garotte,Prediction,Reality check,Ridge regression},
   pages = {352-367},
   publisher = {Elsevier B.V.},
   title = {Forecasting financial and macroeconomic variables using data reduction methods: New empirical evidence},
   volume = {178},
   url = {http://dx.doi.org/10.1016/j.jeconom.2013.08.033},
   year = {2014},
}
@article{,
   abstract = {The term now-casting is a contraction for now and forecasting and has been used for a long time in meteorology and recently also in economics. In this chapter we survey recent developments in economic now-casting with special focus on those models that formalize key features of how market participants and policymakers read macroeconomic data releases in real-time, which involves monitoring many data, forming expectations about them and revising the assessment on the state of the economy whenever realizations diverge sizeably from those expectations. © 2013 Elsevier B.V.},
   author = {Marta Bańbura and Domenico Giannone and Michele Modugno and Lucrezia Reichlin},
   doi = {10.1016/B978-0-444-53683-9.00004-9},
   issn = {15740706},
   issue = {15},
   journal = {Handbook of Economic Forecasting},
   keywords = {Dynamic factor model,High-dimensional data,Macroeconomic forecasting,Macroeconomic news,Mixed frequency,Real-time data},
   pages = {195-237},
   title = {Now-casting and the real-time data flow},
   volume = {2},
   year = {2013},
}
@article{Castle2013,
   abstract = {We consider the reasons for nowcasting, how nowcasts can best be achieved, and the use and timing of information. The existence of contemporaneous data such as surveys is a major difference from forecasting, but many of the recent lessons about forecasting remain relevant. Given the extensive disaggregation over variables underlying flash estimates of aggregates, we show that automatic model selection can play a valuable role, especially when location shifts would otherwise induce nowcast failure. Thus, we address nowcasting when location shifts occur, probably with measurement errors. We describe impulse-indicator saturation as a potential solution to such shifts, noting its relation to intercept corrections and to robust methods to avoid systematic nowcast failure. We propose a nowcasting strategy, building models of all disaggregate series by automatic methods, forecasting all variables before the end of each period, testing for shifts as available measures arrive, and adjusting forecasts of cognate missing series if substantive discrepancies are found. An alternative is switching to robust forecasts when breaks are detected. We apply a variant of this strategy to nowcast UK GDP growth, seeking pseudo real-time data availability. JEL classifications: C52, C51.},
   author = {Jennifer L Castle and David F Hendry and Oleg I Kitov and Jennifer L Castle and David F Hendry and Oleg I Kitov},
   issue = {674},
   keywords = {autometrics,contemporaneous information,forecasting,impulse-indicator saturation,location shifts,nowcasting},
   title = {DEPARTMENT OF ECONOMICS DISCUSSION PAPER SERIES FORECASTING AND NOWCASTING MACROECONOMIC VARIABLES : A METHODOLOGICAL OVERVIEW Forecasting and Nowcasting Macroeconomic Variables : A Methodological Overview},
   year = {2013},
}
@article{Are2013,
   author = {Knut Are and Aastveit Francesco and Ravazzolo Herman},
   keywords = {aastveit,bayesian filtering,carlo nowcasting,density forecast combination,knut-are,no,norges bank,norges-bank,of the authors and,real-time data,sequential monte,should not be attributed,survey forecast,the views expressed in,this paper are those,to norges bank},
   title = {Nowcasting the Business Cycle in an Uncertain Enviroment ∗},
   year = {2013},
}
@article{,
   abstract = {Most economic variables are released with a lag, making it difficult for policy-makers to make an accurate assessment of current conditions. This paper explores whether observing Internet browsing habits can inform practitioners about aggregate consumer behavior in an emerging market. Using data on Google search queries, we introduce an index of online interest in automobile purchases in Chile and test whether it improves the fit and efficiency of nowcasting models for automobile sales. Despite relatively low rates of Internet usage among the population, we find that models incorporating our Google Trends Automotive Index outperform benchmark specifications in both in-sample and out-of-sample nowcasts, provide substantial gains in information delivery times, and are better at identifying turning points in the sales data. Copyright © 2011 John Wiley & Sons, Ltd.},
   author = {Yan Carrière-Swallow and Felipe Labbé},
   doi = {10.1002/for.1252},
   issn = {02776693},
   issue = {4},
   journal = {Journal of Forecasting},
   keywords = {Google Trends,emerging markets,forecast accuracy,nowcasting},
   pages = {289-298},
   title = {Nowcasting with Google trends in an emerging market},
   volume = {32},
   year = {2013},
}
@article{Thorsrud2013,
   abstract = {We develop a theory of low-frequency movements in inflation expectations, and use it to interpret joint dynamics of inflation and inflation expectations for the United States and other countries over the post-war period. In our theory long-run inflation expectations are endogenous. They are driven by short-run inflation surprises, in a way that depends on recent forecasting performance and monetary policy. This distinguishes our theory from common explanations of low-frequency properties of inflation. The model, estimated using only inflation and short-term forecasts from professional surveys, accurately predicts observed measures of long-term inflation expectations and identifies episodes of unanchored expectations. |},
   author = {Leif Anders Thorsrud},
   keywords = {keywords},
   title = {Centre for Applied Macroeconomic Analysis},
   year = {2013},
}
@article{Narr2012,
   abstract = {Millions of tweets posted daily contain opinions and sentiment of users in a variety of languages. Sentiment classification can benefit companies by providing data for analyzing customer feed-back for products or conducting market research. Sentiment classifiers need to be able to handle tweets in multiple languages to cover a larger portion of the available tweets. Traditional clas-sifiers are however often language specific and require much work to be applied to a differ-ent language. We analyze the characterstics and feasibility of a language-independent, semi-supervised sentiment classification approach for tweets. We use emoticons as noisy labels to gen-erate training data from a completely raw set of tweets. We train a Nave Bayes classifier on our data and evaluate it on over 10000 tweets in 4 languages that were human annotated using the Mechanical Turk platform. As part of our contri-bution, we make the sentiment evaluation dataset publicly available. We present an evaluation of the performance of classifiers for each of the 4 languages and of the effects of using multilingual classifiers on tweets of mixed languages. Our ex-periments show that the classification approach can be applied effectively for multiple languages without requiring extra effort per additional lan-guage.},
   author = {Sascha Narr and Michael Hulfenhaus and Sahin Albayrak},
   journal = {Knowledge Discovery and Machine Learning (KDML), LWA},
   pages = {12-14},
   title = {Language-independent Twitter sentiment analysis},
   year = {2012},
}
@article{Varian2012,
   abstract = {Can Google queries help predict economic activity? The answer depends on what you mean by "predict." Google Trends and Google Insights for Search provide a real time report on query volume, while economic data is typically released several days after the close of the month. Given this time lag, it is not implausible that Google queries in a category like "Automotive/Vehicle Shopping" during the first few weeks of March may help predict what actual March automotive sales will be like when the official data is released halfway through April. That famous economist Yogi Berra once said "It's tough to make predictions, especially about the future." This inspired our approach: let us lower the bar and just try to predict the present. Our work to date is summarized in a paper called Predicting the Present with Google Trends. We find that Google Trends data can help improve forecasts of the current level of activity for a number of different economic time series, including automobile sales, home sales, retail sales, and travel behavior. Even predicting the present is useful, since it may help identify "turning points" in economic time series. If people start doing significantly more searches for "Real Estate Agents" in a certain location, it is tempting to think that house sales might increase in that area in the near future. Our paper outlines one approach to short-term economic prediction, but we expect that there are several other interesting ideas out there. So we suggest that forecasting wannabes download some Google Trends data and try to relate it to other economic time series. If you find an interesting pattern, post your findings on a website and send a link to econ-forecast@google.com. We'll report on the most interesting results in a later blog post. It has been said that if you put a million monkeys in front of a million computers, you would eventually produce an accurate economic forecast. Let's see how well that theory works.},
   author = {Hal R. Varian and Hyunyoung Choi},
   doi = {10.2139/ssrn.1659302},
   journal = {SSRN Electronic Journal},
   title = {Predicting the Present with Google Trends},
   year = {2012},
}
@article{Giannone2008,
   abstract = {A formal method is developed for evaluating the marginal impact that intra-monthly data releases have on current-quarter forecasts (nowcasts) of real gross domestic product (GDP) growth. The method can track the real-time flow of the type of information monitored by central banks because it can handle large data sets with staggered data-release dates. Each time new data are released, the nowcasts are updated on the basis of progressively larger data sets that, reflecting the unsynchronized data-release dates, have a "jagged edge" across the most recent months. © 2008 Elsevier B.V.},
   author = {Domenico Giannone and Lucrezia Reichlin and David Small},
   doi = {10.1016/j.jmoneco.2008.05.010},
   issn = {03043932},
   issue = {4},
   journal = {Journal of Monetary Economics},
   keywords = {Factor model,Forecasting,Monetary policy,Nowcast,Real-time data},
   pages = {665-676},
   title = {Nowcasting: The real-time informational content of macroeconomic data},
   volume = {55},
   year = {2008},
}
@article{Gibson2007,
   abstract = {The skew, irrespective of the mean and variance, of investors' interest rate expectations may affect required bond yields over expected short rates. Indeed, evidence suggests that the near-term skew of the option-implied distribution of expected short-term interest rates correlates with distant-horizon term premiums, as derived from a latent-factor affine term structure model (ATSM). Reduced-form models that include skew generally fit the data well and actually better "explain" variation in the term premium during the so-called "conundrum" than during other periods of the May 1989 to May 2006 sample. Moreover, estimates suggest that skew accounts for over half of the movement in term premiums during the "conundrum," considerably more than any other correlate. Caveats regard the term structure of skew as well as alternative measures of the term premium. Indeed, regression analysis of movements in term premiums is plagued by specification bias on both the left- and right-hand-side of the equation.},
   author = {Michael S Gibson},
   isbn = {2024523722},
   issue = {3},
   journal = {Finance and Economics},
   pages = {20},
   title = {Finance and Economics Discussion Series Divisions of Research & Statistics and Monetary Affairs Federal Reserve Board , Washington , D . C . Credit Derivatives and Risk Management},
   volume = {32},
   url = {http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1750286},
   year = {2007},
}
@book{,
   isbn = {9789491602733},
   title = {GDP Growth : Nowcasting Nowcasting Nowcasting Nowcasting Growth Growth Nowcast Growth Growth Nowcasting GDP Growth : statistical models versus professional analysts},
}
@article{,
   author = {William A Barnett},
   keywords = {c32,cation,dynamic factor,e27,e31,e32,gabriel perez-quiros,hashem pesaran,jel classi,michael bauer,michael mccracken,missing data,mixed frequency,monetary policy,nonlinear,nowcasting,ragged edges,real-time,structural breaks,thank maximo camacho,we would like to},
   pages = {1-27},
   title = {Real-Time Nowcasting Nominal GDP Under Structural Break},
}
